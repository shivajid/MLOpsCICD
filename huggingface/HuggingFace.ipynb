{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d1b56d-26bf-48cb-b49a-53cb716b4d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-08-23 20:42:48.203330: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8411cd5-f1a8-4b7f-a7a8-e8dca821cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading config.json: 100%|██████████| 629/629 [00:00<00:00, 845kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 255M/255M [00:03<00:00, 74.3MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 61.3kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 226k/226k [00:00<00:00, 2.00MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175c610d-5c94-4d83-986b-7e7f127b7059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997456669807434}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"You are an idiot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e80240-35de-42d8-849c-e2a5969cec93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8406656980514526}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Has everyone who’s liked this read all the replies- including one that (I believe) conclusively debunks the central claim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686ce66b-c9ae-4627-8f02-b7f6e9e4ae9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9712600708007812}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"The apt command uses the dpkg command underneath it, but apt is more popular and easier to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1eb380-4c2b-4b03-a595-c58d685d8c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading config.json: 100%|██████████| 665/665 [00:00<00:00, 778kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 523M/523M [00:07<00:00, 77.1MB/s] \n",
      "Downloading vocab.json: 100%|██████████| 0.99M/0.99M [00:00<00:00, 6.11MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 446k/446k [00:00<00:00, 3.13MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.29M/1.29M [00:00<00:00, 7.80MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py:1207: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to define your data type within your project; in our example, we will make one object and create another.\\n\\nAfter you have worked with them, have a look at the code below. The data'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "951c3d26-c9f0-4f76-9d81-57eae1ed31bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I was climbing a tree with my wife and I realized that I had not brought the equipment to climb down at that time. But I told a number of friends that I didn't get in a car for that long and that they had a great experience\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"I was climbing a tree with my wife and I realized that I had not brought the equipment to climb down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ed093-64dd-44f5-a5d1-b704957d30b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
