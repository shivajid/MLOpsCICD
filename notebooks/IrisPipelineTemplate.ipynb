{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ca9fc-7334-4a65-bfd6-5017f62a39bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f102b0c9-66b0-46fb-95cf-e8d51edc8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Please update the project id before running the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dead7c3b-78ea-4de2-92aa-ad5a4083c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../pipeline/pipeline_source.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../pipeline/pipeline_source.py\n",
    "#This is a simple pipeline that is used to load and run pipeline\n",
    "\n",
    "import kfp\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform as aip\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "# Change the Project ID\n",
    "#PROJECT_ID =\"[YOUR PROJECT ID]\"\n",
    "#BUCKET_LOC = \"[Your staging bucket locations]\"\n",
    "#PIPELINE_NAME=\"[Your Pipeline Name]\"\n",
    "\n",
    "PROJECT_ID =\"demogct\"\n",
    "BUCKET_LOC = \"gs://demogct/vipipelines/\"\n",
    "PIPELINE_NAME=\"sd-vertex-pipeline\"\n",
    "\n",
    "\n",
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_LOC)\n",
    "\n",
    "@kfp.dsl.pipeline(name=PIPELINE_NAME)\n",
    "def pipeline(project: str = PROJECT_ID):\n",
    "    ds_op = gcc_aip.ImageDatasetCreateOp(\n",
    "        project=project,\n",
    "        display_name=\"flowers\",\n",
    "        gcs_source=\"gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\",\n",
    "        import_schema_uri=aip.schema.dataset.ioformat.image.single_label_classification,\n",
    "    )\n",
    "\n",
    "    training_job_run_op = gcc_aip.AutoMLImageTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=\"train-automl-flowers\",\n",
    "        prediction_type=\"classification\",\n",
    "        model_type=\"CLOUD\",\n",
    "        base_model=None,\n",
    "        dataset=ds_op.outputs[\"dataset\"],\n",
    "        model_display_name=\"train-automl-flowers\",\n",
    "        training_fraction_split=0.7,\n",
    "        validation_fraction_split=0.2,\n",
    "        test_fraction_split=0.1,\n",
    "        budget_milli_node_hours=8000,\n",
    "    )\n",
    "    # 0.1.7 is needed currently to address a bug in the latest container image\n",
    "    gcc_aip.ModelDeployOp.component_spec.implementation.container.image = (\"gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7\")\n",
    " \n",
    "    \n",
    "    endpoint_op = gcc_aip.ModelDeployOp(  \n",
    "         model=training_job_run_op.outputs[\"model\"],\n",
    "         project=\"demogct\"\n",
    "    )\n",
    "  \n",
    "\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"artifacts/image classification_pipeline.json\".replace(\" \", \"_\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f01e575-5b4c-4fa6-8620-8a2866211b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../pipeline/pipeline_execute.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../pipeline/pipeline_execute.py\n",
    "\n",
    "import kfp\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform as aip\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import compiler\n",
    "from datetime import datetime\n",
    "\n",
    "# Change the Project ID\n",
    "#PROJECT_ID =\"[YOUR PROJECT ID]\"\n",
    "#BUCKET_LOC = \"[Your staging bucket locations]\"\n",
    "#PIPELINE_NAME=\"[Your Pipeline Name]\"\n",
    "\n",
    "PROJECT_ID =\"demogct\"\n",
    "BUCKET_LOC = \"gs://demogct/vipipelines/\"\n",
    "PIPELINE_NAME=\"sd-vertex-pipeline\"\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "DISPLAY_NAME = \"flowers_\" + TIMESTAMP\n",
    "PIPELINE_ROOT=\"gs://demogct/vipipelines/\"\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"artifacts/image classification_pipeline.json\".replace(\" \", \"_\"),\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364535f0-8942-467c-9a55-5880e1b05d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TRAIN_VERSION = \"tf-gpu.2-6\"\n",
    "DEPLOY_VERSION = \"tf2-gpu.2-6\"\n",
    "CONTAINER_ARTIFACTS_DIR=\"../artifacts\"\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "dockerfile = f'''FROM {TRAIN_IMAGE}\n",
    "\n",
    "WORKDIR /root\n",
    "\n",
    "RUN pip install google-cloud-pipeline-components==0.1.7 google-cloud-aiplatform google-cloud-storage\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY ../pipelines/pipeline.py /root/pipeline.py\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"pipeline.py\"]\n",
    "'''\n",
    "\n",
    "with open(os.path.join(CONTAINER_ARTIFACTS_DIR, 'Dockerfile'), 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66dc145b-a0e8-4076-8e16-68d02e8c9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY=\"day4-workshop\"\n",
    "INITIALS =\"mayo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84acaff3-d582-4aa8-a480-5dad8a42d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [day4-workshop]\n",
      "Waiting for operation [projects/demogct/locations/us-central1/operations/044bae\n",
      "67-4950-44ba-9eb4-b10436898f74] to complete...done.                            \n",
      "Created repository [day4-workshop].\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create $REPOSITORY --repository-format=docker \\\n",
    "--location=us-central1 --description=f\"{INITIALS} Vertex sample repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f60a897-b1d2-49ab-b6fc-c3fdb458d1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker us-central1-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e3084-65cc-431b-b3e5-0f76fe238f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
